# -*- coding: utf-8 -*-
"""LongformSum.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VwLhSIm6RsiAX1P25ZrDzBg7Db33Ta4N
"""
from transformers import pipeline
from bs4 import BeautifulSoup
import requests
import googletrans
from googletrans import Translator

summarizer = pipeline("summarization")

URL = "https://vnexpress.net/nga-hom-nay-duyet-binh-ky-niem-ngay-chien-thang-4460973.html"

r = requests.get(URL)

soup = BeautifulSoup(r.text, 'html.parser')
results = soup.find_all(['h1', 'p'])
text = [result.text for result in results]
ARTICLE = ' '.join(text)

max_chunk = 500

ARTICLE = ARTICLE.replace('.', '.<eos>')
ARTICLE = ARTICLE.replace('?', '?<eos>')
ARTICLE = ARTICLE.replace('!', '!<eos>')

sentences = ARTICLE.split('<eos>')

current_chunk = 0 
chunks = []

for sentence in sentences:
    if len(chunks) == current_chunk + 1: 
        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:
            chunks[current_chunk].extend(sentence.split(' '))
        else:
            current_chunk += 1
            chunks.append(sentence.split(' '))
    else:
        chunks.append(sentence.split(' '))

for chunk_id in range(len(chunks)):
    chunks[chunk_id] = ' '.join(chunks[chunk_id])

translator = Translator()

translated = translator.translate(chunks, dest='en')

final_text = [trans.text for trans in translated]

res = summarizer(final_text, max_length=200, min_length=30, do_sample=False)

final_com = ' '.join([summ['summary_text'] for summ in res])

pp = translator.translate(final_com, dest=translator.detect(chunks)[0].lang)

with open("summary.txt", "w", encoding="utf-8") as f:
    f.write(pp.text)